
# ğŸ“š StudyGenie

**StudyGenie** is an AI-powered educational tool designed to generate personalized study plans and context-aware prompts using advanced prompt engineering techniques. Built with Python and Flask, it enables users to create optimized learning experiences tailored to their goals.


---

## ğŸš€ Features

* âœ¨ **Dynamic Prompt Generation**: Leverages GPT-like models to generate study prompts and guides.
* ğŸ§  **Context-Aware Prompting**: Utilizes context from user inputs or subjects to enhance response relevance.
* ğŸ—‚ï¸ **Personalized Study Plans**: Creates customized study plans based on topics and user preferences.
* ğŸ“Š **Model Training Notebook**: Includes a Jupyter Notebook for experimenting with or fine-tuning prompt models.
* ğŸŒ **Web Interface**: Simple front-end built with HTML to interact with the AI backend.

---

## ğŸ–¼ï¸ Screenshots

![Screenshot 2025-05-16 161851](https://github.com/user-attachments/assets/ba1410bc-c702-4dee-82a0-4e4570fa3d11)
![Screenshot 2025-05-16 162059](https://github.com/user-attachments/assets/20052099-85cb-45dc-a136-0ec2a066ef5e)
![Screenshot 2025-05-16 161902](https://github.com/user-attachments/assets/a5dccb15-0be7-4e8e-a863-780424b8b787)

---

## ğŸ› ï¸ Tech Stack

* **Backend**: Python, Flask
* **AI & NLP**: OpenAI/GPT-like prompts (manual logic)
* **Frontend**: HTML (Jinja templates)
* **Notebook**: Jupyter, for model training and testing

---

## ğŸ“ Project Structure

```

StudyGenie/
â”œâ”€â”€ advanced\_prompting.py      # Handles advanced prompt engineering
â”œâ”€â”€ app.py                     # Flask app routing and server logic
â”œâ”€â”€ context\_prompt.py          # Contextual enhancement for prompts
â”œâ”€â”€ prompt\_generator.py        # Core prompt generation logic
â”œâ”€â”€ study\_plan.py              # Logic to build study plans
â”œâ”€â”€ ModelTraining.ipynb        # Jupyter Notebook for prompt/model testing
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html             # Basic HTML interface
â””â”€â”€ README.md                  # Project documentation

````

---

## ğŸ”§ Installation & Setup

1. **Install Python dependencies**:

   ```bash
   pip install -r requirements.txt
``

2. **Install Ollama (for running LLMs locally)**:
   Follow instructions from: [https://ollama.com/download](https://ollama.com/download)

3. **Pull and run a model (e.g., LLaMA 2)**:

   ```bash
   ollama run llama2
   ```

   > â„¹ï¸ This step may take a few minutes as the model is downloaded and initialized.

4. **Start the Flask server**:

   ```bash
   python app.py
   ```

5. **Access the application** in your browser at:

   ```
   http://localhost:5000
   ```



## ğŸ§ª Usage

* Navigate to the homepage.
* Enter your study goals or topics.
* Generate study plans and prompts.
* Optionally explore or modify the `ModelTraining.ipynb` for AI model exploration.

---

## ğŸ“ˆ Future Improvements

* User authentication and profiles
* Integration with real AI APIs (e.g., OpenAI)
* Interactive study dashboard
* Mobile-responsive UI

---

## ğŸ“„ License

This project is licensed under the MIT License.

```
